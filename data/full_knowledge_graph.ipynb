{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae54310",
   "metadata": {},
   "source": [
    "# Knowledge Graph Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc725f2",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "The **`data`** folder must be ready, containing:\n",
    "- `rdf/subgraphs/data.tll`\n",
    "\n",
    "The schema folder must contain the ontology:\n",
    "- `rdf/schema/shapes.ttl`\n",
    "- `rdf/schema/skos.ttl`\n",
    "- `rdf/schema/owl.ttl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6910a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941aa36c",
   "metadata": {},
   "source": [
    "### IO Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf39424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rdflib import Graph\n",
    "\n",
    "\n",
    "def load_graph(files_to_load: list[Path]) -> Graph:\n",
    "    graph = Graph()\n",
    "    for path in files_to_load:\n",
    "        graph.parse(path, format=\"turtle\")\n",
    "    return graph\n",
    "\n",
    "\n",
    "def export_graph(graph: Graph, output_path: Path) -> None:\n",
    "    # Ensure the output directory exists\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Export the graph to Turtle format\n",
    "    graph.serialize(destination=output_path, format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d4275",
   "metadata": {},
   "source": [
    "## A-Box Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6109b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, URIRef\n",
    "from rdflib.namespace import RDF, OWL\n",
    "import requests\n",
    "import time\n",
    "\n",
    "SP = Namespace(\"http://example.org/smartphone#\")\n",
    "SPOTLIGHT_URL = \"https://api.dbpedia-spotlight.org/en/annotate\"\n",
    "WIKIDATA_API = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "# Required for Wikidata API\n",
    "HEADERS = {\"User-Agent\": \"SmartphoneKG/1.0 (university project)\"}\n",
    "\n",
    "# Keywords to identify phone-related Wikidata entries\n",
    "PHONE_KEYWORDS = [                          \n",
    "    # Generic                               \n",
    "    \"smartphone\", \"phone model\", \"mobile phone\", \"android\",                          \n",
    "    \"generation of the\", \"series of smartphones\",                               \n",
    "    # Brands                                \n",
    "    \"iphone\", \"apple\", \"samsung\", \"galaxy\", \n",
    "\"google\", \"pixel\",                          \n",
    "    \"xiaomi\", \"redmi\", \"poco\", \"oneplus\",   \n",
    "\"oppo\", \"realme\", \"vivo\", \"iqoo\",           \n",
    "    \"huawei\", \"honor\", \"motorola\", \"moto\",  \n",
    "\"sony\", \"asus\", \"nothing\", \"tecno\",         \n",
    "    # Series                                \n",
    "    \"rog\", \"xperia\", \"zenfone\", \"razr\",     \n",
    "\"nord\", \"narzo\", \"camon\", \"spark\",          \n",
    "    \"pova\", \"nova\", \"mate\", \"magic\", \"fold\",\n",
    "\"flip\", \"edge\", \"note\", \"find\", \"reno\"     \n",
    "]  \n",
    "\n",
    "\n",
    "def query_spotlight(label: str) -> str | None:\n",
    "    \"\"\"Get DBpedia URI for a brand via Spotlight API.\"\"\"\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            SPOTLIGHT_URL,\n",
    "            data={\"text\": f\"{label} company\", \"confidence\": 0.8},\n",
    "            headers={\"Accept\": \"application/json\"},\n",
    "            timeout=10,\n",
    "        )\n",
    "        for res in r.json().get(\"Resources\", []):\n",
    "            if label.lower() in res.get(\"@surfaceForm\", \"\").lower():\n",
    "                return res[\"@URI\"]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_phone_name(uri: str) -> str:\n",
    "    \"\"\"Extract clean phone name from URI, removing brand duplication.\"\"\"\n",
    "    # URI like: .../apple_apple_iphone_16 -> \"iPhone 16\"\n",
    "    raw = uri.split(\"/\")[-1].replace(\"_\", \" \")\n",
    "    # Remove duplicate brand prefix (e.g., \"apple apple\" -> \"apple\")\n",
    "    words = raw.split()\n",
    "    if len(words) >= 2 and words[0].lower() == words[1].lower():\n",
    "        words = words[1:]  # Remove first duplicate\n",
    "    # Capitalize properly for search\n",
    "    return \" \".join(words).title()\n",
    "\n",
    "\n",
    "def query_wikidata(phone_name: str) -> str | None:\n",
    "    \"\"\"Search Wikidata for a phone model.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            WIKIDATA_API,\n",
    "            params={\n",
    "                \"action\": \"wbsearchentities\",\n",
    "                \"search\": phone_name,\n",
    "                \"language\": \"en\",\n",
    "                \"type\": \"item\",\n",
    "                \"limit\": 5,\n",
    "                \"format\": \"json\",\n",
    "            },\n",
    "            headers=HEADERS,\n",
    "            timeout=10,\n",
    "        )\n",
    "        for result in r.json().get(\"search\", []):\n",
    "            desc = result.get(\"description\", \"\").lower()\n",
    "            label = result.get(\"label\", \"\").lower()\n",
    "            # Filter for smartphone-related entries\n",
    "            if any(kw in desc or kw in label for kw in PHONE_KEYWORDS):\n",
    "                return f\"http://www.wikidata.org/entity/{result['id']}\"\n",
    "    except Exception as e:\n",
    "        print(f\"  Wikidata error: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def perform_linkage(graph: Graph) -> Graph:\n",
    "    \"\"\"Return a graph containing owl:sameAs links for brands (DBpedia) and phones (Wikidata).\"\"\"\n",
    "\n",
    "    result = Graph()\n",
    "    result.bind(\"owl\", OWL)\n",
    "    result.bind(\"sp\", SP)\n",
    "\n",
    "    # Link brands to DBpedia\n",
    "    brands = [s for s in graph.subjects(RDF.type, SP.Brand) if isinstance(s, URIRef)]\n",
    "\n",
    "    for uri in brands:\n",
    "        name = str(uri).split(\"/\")[-1].replace(\"_\", \" \")\n",
    "        if dbpedia := query_spotlight(name):\n",
    "            result.add((uri, OWL.sameAs, URIRef(dbpedia)))\n",
    "            print(f\"+ Brand: {name} -> {dbpedia}\")\n",
    "\n",
    "    # Link phones to Wikidata\n",
    "    phones = [s for s in graph.subjects(RDF.type, SP.BasePhone) if isinstance(s, URIRef)]\n",
    "    linked_count = 0\n",
    "\n",
    "    for uri in phones:\n",
    "        phone_name = clean_phone_name(str(uri))\n",
    "\n",
    "        # Sleep to avoid rate limiting\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "        if wikidata := query_wikidata(phone_name):\n",
    "            result.add((uri, OWL.sameAs, URIRef(wikidata)))\n",
    "            print(f\"+ Phone: {phone_name} -> {wikidata}\")\n",
    "            linked_count += 1\n",
    "\n",
    "    print(f\"\\nGenerated {len(result)} owl:sameAs links ({linked_count} phones)\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745b96c",
   "metadata": {},
   "source": [
    "## T-Box Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f605a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import TypedDict\n",
    "\n",
    "import requests\n",
    "from rdflib import Graph, Namespace, URIRef\n",
    "from rdflib.namespace import OWL, RDFS, SKOS\n",
    "\n",
    "SP = Namespace(\"http://example.org/smartphone#\")\n",
    "\n",
    "LOV_API = \"https://lov.linkeddata.es/dataset/lov/api/v2/term/search\"\n",
    "OPENAI_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "TRUSTED_VOCABS = [\"schema.org\", \"dbpedia.org\", \"wikidata.org\", \"purl.org/goodrelations\",\n",
    "                  \"xmlns.com/foaf\", \"purl.org/dc\", \"w3.org/2004/02/skos\"]\n",
    "\n",
    "RELATION_PREDICATES: dict[str, URIRef] = {\n",
    "    \"equivalent\": OWL.equivalentClass,\n",
    "    \"subclass\": RDFS.subClassOf,\n",
    "    \"subproperty\": RDFS.subPropertyOf,\n",
    "    \"exact\": SKOS.exactMatch,\n",
    "    \"close\": SKOS.closeMatch,\n",
    "}\n",
    "\n",
    "MANUAL_ALIGNMENTS: list[tuple[URIRef, URIRef, URIRef]] = [\n",
    "    (SP.BasePhone, RDFS.subClassOf, URIRef(\"http://schema.org/Product\")),\n",
    "    (SP.BasePhone, SKOS.exactMatch, URIRef(\"http://www.wikidata.org/entity/Q22645\")),\n",
    "    (SP.User, RDFS.subClassOf, URIRef(\"http://schema.org/Person\")),\n",
    "    (SP.User, RDFS.subClassOf, URIRef(\"http://xmlns.com/foaf/0.1/Person\")),\n",
    "    (SP.TagSentiment, SKOS.closeMatch, URIRef(\"http://schema.org/Rating\")),\n",
    "    (SP.manufactures, SKOS.closeMatch, URIRef(\"http://schema.org/manufacturer\")),\n",
    "    (SP.manufactures, SKOS.closeMatch, URIRef(\"http://dbpedia.org/ontology/manufacturer\")),\n",
    "    (SP.likes, SKOS.closeMatch, URIRef(\"http://xmlns.com/foaf/0.1/interest\")),\n",
    "    (SP.supportsNFC, SKOS.closeMatch, URIRef(\"http://dbpedia.org/ontology/feature\")),\n",
    "]\n",
    "\n",
    "\n",
    "class LOVCandidate(TypedDict):\n",
    "    uri: str\n",
    "    label: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "class LLMChoice(TypedDict):\n",
    "    uri: str\n",
    "    relation: str\n",
    "\n",
    "\n",
    "def query_lov(term: str, term_type: str) -> list[LOVCandidate]:\n",
    "    \"\"\"Query LOV API for alignment candidates.\"\"\"\n",
    "    candidates: dict[str, LOVCandidate] = {}\n",
    "    queries = [term, re.sub(r'([A-Z])', r' \\1', term).strip().lower()]\n",
    "\n",
    "    for q in queries:\n",
    "        try:\n",
    "            r = requests.get(LOV_API, params={\"q\": q, \"type\": term_type, \"page_size\": 20}, timeout=10)\n",
    "            for res in r.json().get(\"results\", []):\n",
    "                uri: str | None = res.get(\"uri\", [None])[0]\n",
    "                if uri and any(v in uri for v in TRUSTED_VOCABS) and uri not in candidates:\n",
    "                    candidates[uri] = {\n",
    "                        \"uri\": uri,\n",
    "                        \"label\": res.get(\"prefixedName\", [\"\"])[0],\n",
    "                        \"score\": res.get(\"score\", 0),\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            print(f\"  LOV error: {e}\")\n",
    "\n",
    "    return list(candidates.values())[:20]\n",
    "\n",
    "\n",
    "def ask_llm(name: str, term_type: str, comment: str, candidates: list[LOVCandidate]) -> list[LLMChoice]:\n",
    "    \"\"\"Ask LLM to choose best alignments from candidates.\"\"\"\n",
    "    if not candidates:\n",
    "        return []\n",
    "\n",
    "    cand_text = \"\\n\".join(f\"  {i+1}. {c['uri']} ({c['label']}, score={c['score']:.2f})\"\n",
    "                          for i, c in enumerate(candidates))\n",
    "\n",
    "    prompt = f\"\"\"You are an expert in ontology alignment for Linked Open Data. Your task is to align terms from a smartphone domain ontology (namespace: http://example.org/smartphone#) to well-known external vocabularies.\n",
    "\n",
    "## ONTOLOGY TERM TO ALIGN\n",
    "- **Local name:** {name}\n",
    "- **Type:** {term_type}\n",
    "- **Description:** {comment or 'No description available'}\n",
    "- **Domain context:** This term belongs to a smartphone/mobile device ontology covering phones, brands, specifications (RAM, storage, battery, display), features (5G, NFC, wireless charging), pricing, user reviews, and sentiment analysis.\n",
    "\n",
    "## CANDIDATE MATCHES FROM LINKED OPEN VOCABULARIES\n",
    "{cand_text}\n",
    "\n",
    "## YOUR TASK\n",
    "Select ONLY semantically appropriate matches (up to 10). For each match, specify the relationship type:\n",
    "\n",
    "- **\"equivalent\"** → owl:equivalentClass/Property - Identical meaning, can be used interchangeably\n",
    "- **\"subclass\"** / **\"subproperty\"** → rdfs:subClassOf/subPropertyOf - Our term is more specific than the external one\n",
    "- **\"exact\"** → skos:exactMatch - Same concept, suitable for cross-vocabulary linking\n",
    "- **\"close\"** → skos:closeMatch - Similar but not identical meaning, useful for discovery\n",
    "\n",
    "## CRITICAL SEMANTIC CONSTRAINTS - READ CAREFULLY\n",
    "\n",
    "**Understand the actual meaning of each candidate before matching:**\n",
    "- Read the URI path carefully: \"BusinessEntity\" means organization/company, NOT a product\n",
    "- \"fileSize\" means size of a file in bytes, NOT storage capacity of a device\n",
    "- \"foaf:phone\" is for telephone NUMBERS (strings like \"+1-555-1234\"), NOT phone devices\n",
    "- \"Camera\" as a class means a camera device, NOT a phone with a good camera\n",
    "\n",
    "**REJECT matches that are:**\n",
    "- Lexically similar but semantically different (e.g., \"phone\" in phoneName vs foaf:phone)\n",
    "- Wrong domain (e.g., a Product class matched to an Organization/BusinessEntity class)\n",
    "- Wrong measurement type (e.g., storage capacity matched to file size)\n",
    "- Overly generic when specific alternatives exist\n",
    "\n",
    "**Quality over quantity:** Return FEWER but CORRECT matches. An empty result is better than wrong alignments.\n",
    "\n",
    "## GUIDELINES\n",
    "- Prefer Schema.org and DBpedia for broad interoperability\n",
    "- Phone subclasses (like HighResolutionCameraPhone) should align to schema:Product or similar, NOT to Camera\n",
    "- Property names about device specs should match device/product properties, not unrelated concepts\n",
    "- Each URI should appear only ONCE with its best-fitting relation\n",
    "\n",
    "## RESPONSE FORMAT\n",
    "Return ONLY a JSON object with a \"matches\" array:\n",
    "{{\"matches\": [{{\"uri\": \"http://schema.org/Product\", \"relation\": \"subclass\"}}, ...]}}\n",
    "\n",
    "If no good matches exist, return: {{\"matches\": []}}\"\"\"\n",
    "\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            OPENAI_URL,\n",
    "            headers={\n",
    "                \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "            },\n",
    "            json={\n",
    "                \"model\": OPENAI_MODEL,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"response_format\": {\"type\": \"json_object\"},\n",
    "            },\n",
    "            timeout=60,\n",
    "        )\n",
    "        content = r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        parsed = json.loads(content)\n",
    "        # Handle both {\"matches\": [...]} and [...] formats\n",
    "        if isinstance(parsed, list):\n",
    "            return parsed\n",
    "        if isinstance(parsed, dict) and \"matches\" in parsed:\n",
    "            return parsed[\"matches\"]\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"  LLM error: {e}, using top LOV match\")\n",
    "        if candidates:\n",
    "            return [{\"uri\": candidates[0][\"uri\"], \"relation\": \"close\"}]\n",
    "    return []\n",
    "\n",
    "def perform_alignment(graph: Graph) -> Graph:\n",
    "    \"\"\"Return a graph containing only the generated ontology alignments.\"\"\"\n",
    "\n",
    "    result = Graph()\n",
    "    result.bind(\"owl\", OWL)\n",
    "    result.bind(\"rdfs\", RDFS)\n",
    "    result.bind(\"skos\", SKOS)\n",
    "    result.bind(\"sp\", SP)\n",
    "\n",
    "    seen: dict[tuple[str, str], URIRef] = {}\n",
    "\n",
    "    # Apply manual alignments into result graph\n",
    "    for s, p, o in MANUAL_ALIGNMENTS:\n",
    "        key = (str(s), str(o))\n",
    "        if key not in seen:\n",
    "            result.add((s, p, o))\n",
    "            seen[key] = p\n",
    "            print(f\"+ manual: {s.split('#')[-1]} -> {o}\")\n",
    "\n",
    "    # Collect ontology terms from the original graph\n",
    "    terms: dict[URIRef, str] = {}\n",
    "\n",
    "    for uri in graph.subjects(None, OWL.Class):\n",
    "        if isinstance(uri, URIRef) and str(uri).startswith(str(SP)):\n",
    "            terms[uri] = \"class\"\n",
    "\n",
    "    for uri in graph.subjects(None, None):\n",
    "        if isinstance(uri, URIRef) and str(uri).startswith(str(SP)):\n",
    "            if (uri, None, OWL.ObjectProperty) in graph or (uri, None, OWL.DatatypeProperty) in graph:\n",
    "                terms[uri] = \"property\"\n",
    "\n",
    "    print(f\"Aligning {len(terms)} terms…\")\n",
    "\n",
    "    for uri, term_type in terms.items():\n",
    "        name = str(uri).split(\"#\")[-1]\n",
    "        comment = str(next(graph.objects(uri, RDFS.comment), \"\"))\n",
    "\n",
    "        candidates = query_lov(name, term_type)\n",
    "        choices = ask_llm(name, term_type, comment, candidates)\n",
    "\n",
    "        seen_uris: set[str] = set()\n",
    "        for choice in choices:\n",
    "            if not isinstance(choice, dict):\n",
    "                continue\n",
    "            ext = choice.get(\"uri\")\n",
    "            if not ext or ext in seen_uris:\n",
    "                continue\n",
    "\n",
    "            seen_uris.add(ext)\n",
    "\n",
    "            key = (str(uri), ext)\n",
    "            if key in seen:\n",
    "                continue\n",
    "\n",
    "            relation = choice.get(\"relation\", \"close\")\n",
    "            pred = RELATION_PREDICATES.get(relation, SKOS.closeMatch)\n",
    "\n",
    "            result.add((uri, pred, URIRef(ext)))\n",
    "            seen[key] = pred\n",
    "            print(f\"+ {name} -> {relation}: {ext}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df573d",
   "metadata": {},
   "source": [
    "## Unstructured Data to RDF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a82596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "def get_unstructured_data_as_rdf() -> Graph:\n",
    "    raise NotImplementedError(\"Function get_unstructured_data_as_rdf is not yet implemented.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acfdd56",
   "metadata": {},
   "source": [
    "## Materialize Constructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f47271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "SPARQL_CONSTRUCTS=[\n",
    "    (\"HighResolutionCameraPhone\", \"\"\"\n",
    "        PREFIX sp: <http://example.org/smartphone#>\n",
    "        CONSTRUCT { ?phone a sp:HighResolutionCameraPhone }\n",
    "        WHERE { ?phone a sp:BasePhone ; sp:mainCameraMP ?mp . FILTER(?mp >= 100) }\n",
    "    \"\"\"),\n",
    "    (\"LargeBatteryPhone\", \"\"\"\n",
    "        PREFIX sp: <http://example.org/smartphone#>\n",
    "        CONSTRUCT { ?phone a sp:LargeBatteryPhone }\n",
    "        WHERE { ?phone a sp:BasePhone ; sp:batteryCapacityMah ?mah . FILTER(?mah >= 5000) }\n",
    "    \"\"\"),\n",
    "    (\"BudgetPhone\", \"\"\"\n",
    "        PREFIX sp: <http://example.org/smartphone#>\n",
    "        PREFIX spv: <http://example.org/smartphone/vocab/>\n",
    "        CONSTRUCT { ?config sp:hasPriceSegment spv:Budget }\n",
    "        WHERE {\n",
    "            ?config a sp:PhoneConfiguration .\n",
    "            ?offering sp:forConfiguration ?config ; sp:priceValue ?price .\n",
    "            FILTER(?price < 400)\n",
    "            FILTER NOT EXISTS {\n",
    "                ?other sp:forConfiguration ?config ; sp:priceValue ?lower .\n",
    "                FILTER(?lower < ?price)\n",
    "            }\n",
    "        }\n",
    "    \"\"\"),\n",
    "    (\"MidRangePhone\", \"\"\"\n",
    "        PREFIX sp: <http://example.org/smartphone#>\n",
    "        PREFIX spv: <http://example.org/smartphone/vocab/>\n",
    "        CONSTRUCT { ?config sp:hasPriceSegment spv:MidRange }\n",
    "        WHERE {\n",
    "            ?config a sp:PhoneConfiguration .\n",
    "            ?offering sp:forConfiguration ?config ; sp:priceValue ?price .\n",
    "            FILTER(?price >= 400 && ?price <= 900)\n",
    "            FILTER NOT EXISTS {\n",
    "                ?other sp:forConfiguration ?config ; sp:priceValue ?lower .\n",
    "                FILTER(?lower < ?price)\n",
    "            }\n",
    "        }\n",
    "    \"\"\"),\n",
    "    (\"FlagshipPhone\", \"\"\"\n",
    "        PREFIX sp: <http://example.org/smartphone#>\n",
    "        PREFIX spv: <http://example.org/smartphone/vocab/>\n",
    "        CONSTRUCT { ?config sp:hasPriceSegment spv:Flagship }\n",
    "        WHERE {\n",
    "            ?config a sp:PhoneConfiguration .\n",
    "            ?offering sp:forConfiguration ?config ; sp:priceValue ?price .\n",
    "            FILTER(?price > 900)\n",
    "            FILTER NOT EXISTS {\n",
    "                ?other sp:forConfiguration ?config ; sp:priceValue ?lower .\n",
    "                FILTER(?lower < ?price)\n",
    "            }\n",
    "        }\n",
    "    \"\"\"),\n",
    "]\n",
    "\n",
    "def materialize_construct_rules(\n",
    "    graph: Graph,\n",
    ") -> Graph:\n",
    "    \"\"\"\n",
    "    Execute SPARQL CONSTRUCT rules and return a graph\n",
    "    containing only the inferred triples.\n",
    "    \"\"\"\n",
    "\n",
    "    result = Graph()\n",
    "\n",
    "    for _, query in SPARQL_CONSTRUCTS:\n",
    "        constructed = graph.query(query).graph\n",
    "        if constructed:\n",
    "            result += constructed\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3500579",
   "metadata": {},
   "source": [
    "## Apply OWL Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "635339c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "import owlrl\n",
    "\n",
    "def apply_owl_rl_reasoning(graph: Graph) -> Graph:\n",
    "    \"\"\"\n",
    "    Run OWL RL reasoning and return only the inferred triples.\n",
    "    \"\"\"\n",
    "\n",
    "    base_size = len(graph)\n",
    "\n",
    "    temp = Graph()\n",
    "    temp += graph\n",
    "\n",
    "    owlrl.DeductiveClosure(owlrl.OWLRL_Semantics).expand(temp)\n",
    "\n",
    "    inferred = Graph()\n",
    "    for triple in temp:\n",
    "        if triple not in graph:\n",
    "            inferred.add(triple)\n",
    "\n",
    "    return inferred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f86c53",
   "metadata": {},
   "source": [
    "# Execute Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f747e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base facts and ontology layers into the knowledge graph\n",
    "kg = load_graph([\n",
    "    # Facts\n",
    "    Path(\"rdf/subgraphs/data.ttl\"),\n",
    "    # Schema\n",
    "    Path(\"rdf/schema/owl.ttl\"),\n",
    "    Path(\"rdf/schema/shapes.ttl\"),\n",
    "    Path(\"rdf/schema/skos.ttl\")\n",
    "])\n",
    "\n",
    "# Persist the initial graph snapshot\n",
    "export_graph(kg, Path(\"rdf/subgraphs/knowledge_graph_initial.ttl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89f4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_path = Path(\"rdf/subgraphs/links.ttl\")\n",
    "\n",
    "if links_path.exists():\n",
    "    kg += load_graph([links_path])\n",
    "else:\n",
    "    links = perform_linkage(kg)\n",
    "    export_graph(links, links_path)\n",
    "    kg += links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd7a98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_path = Path(\"rdf/subgraphs/alignments.ttl\")\n",
    "\n",
    "if alignments_path.exists():\n",
    "    kg += load_graph([alignments_path])\n",
    "else:\n",
    "    alignments = perform_alignment(kg)\n",
    "    export_graph(alignments, alignments_path)\n",
    "    kg += alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6a26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstructured_path = Path(\"rdf/subgraphs/unstructured.ttl\")\n",
    "\n",
    "# if unstructured_path.exists():\n",
    "#     kg += load_graph([unstructured_path])\n",
    "# else:\n",
    "#     unstructured = get_unstructured_data_as_rdf()\n",
    "#     export_graph(unstructured, unstructured_path)\n",
    "#     kg += unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1399411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructed_path = Path(\"rdf/subgraphs/constructed.ttl\")\n",
    "\n",
    "if constructed_path.exists():\n",
    "    kg += load_graph([constructed_path])\n",
    "else:\n",
    "    constructed = materialize_construct_rules(kg)\n",
    "    export_graph(constructed, constructed_path)\n",
    "    kg += constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54ec7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_path = Path(\"rdf/subgraphs/inferred.ttl\")\n",
    "\n",
    "if inferred_path.exists():\n",
    "    kg += load_graph([inferred_path])\n",
    "else:\n",
    "    inferred = apply_owl_rl_reasoning(kg)\n",
    "    export_graph(inferred, inferred_path)\n",
    "    kg += inferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de3f08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final export\n",
    "export_graph(kg, Path(\"rdf/knowledge_graph_full.ttl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00a1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multicourse-project-m2-last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
